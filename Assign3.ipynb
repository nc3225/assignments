{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f144d40-5e55-4cf4-b050-48c35f71b455",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup: Install Required Packages\n",
    "#### Run this cell first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92119b05-4c58-47e9-8e7b-2e0dd341024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to install these\n",
    "# pip install pooch requests\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39bf8e8-b61b-4242-bfe8-d610803d1b10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 1: Working with JSON Data\n",
    "#### JSON (JavaScript Object Notation) is commonly used for web APIs. Many climate data services provide JSON outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158040f-6dce-4f40-94a3-23f6d78454c2",
   "metadata": {},
   "source": [
    "### Provided Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dfa8f8e-d695-4dd2-8f85-dd133d60a4f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station: USC00305800\n",
      "Location: {'latitude': 40.7789, 'longitude': -73.9692}\n",
      "First observation: {'date': '2023-01-01', 'temperature': 32, 'precipitation': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "# Here's a sample JSON structure similar to what APIs return\n",
    "sample_json = '''\n",
    "{\n",
    "  'station': 'USC00305800',\n",
    "  'name': 'New York Central Park',\n",
    "  'location': {\n",
    "    'latitude': 40.7789,\n",
    "    'longitude': -73.9692\n",
    "  },\n",
    "  'observations': [\n",
    "    {'date': '2023-01-01', 'temperature': 32, 'precipitation': 0.0},\n",
    "    {'date': '2023-01-02', 'temperature': 28, 'precipitation': 0.5},\n",
    "    {'date': '2023-01-03', 'temperature': 35, 'precipitation': 0.0},\n",
    "    {'date': '2023-01-04', 'temperature': 38, 'precipitation': 0.2},\n",
    "    {'date': '2023-01-05', 'temperature': 41, 'precipitation': 0.0}\n",
    "  ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Parse the JSON\n",
    "data = json.loads(sample_json)\n",
    "\n",
    "# Access nested data\n",
    "print('Station:', data['station'])\n",
    "print('Location:', data['location'])\n",
    "print('First observation:', data['observations'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470cb76-b5cd-4977-9e1d-bbc7a43c72c8",
   "metadata": {},
   "source": [
    "### Your Tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e25990f-be12-401b-84f5-a85e21f9e636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2023-01-01', 'temperature': 32, 'precipitation': 0.0}, {'date': '2023-01-02', 'temperature': 28, 'precipitation': 0.5}, {'date': '2023-01-03', 'temperature': 35, 'precipitation': 0.0}, {'date': '2023-01-04', 'temperature': 38, 'precipitation': 0.2}, {'date': '2023-01-05', 'temperature': 41, 'precipitation': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "print(data['observations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d080dc75-ada9-4f69-9245-11f387dab5f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date, Temperature\n",
      "2023-01-01, 32\n",
      "2023-01-02, 28\n",
      "2023-01-03, 35\n",
      "2023-01-04, 38\n",
      "2023-01-05, 41\n",
      "Total Temp: 174\n",
      "Count:5\n",
      "Average temperature: 34.8째F\n"
     ]
    }
   ],
   "source": [
    "# 1. Extract and print all dates and temperatures (8 points)\n",
    "### {} | [] | () all mean something different!!!! \n",
    "\n",
    "total_temp = 0\n",
    "count = 0\n",
    "\n",
    "print('Date, Temperature')\n",
    "for obs in data['observations']:\n",
    "    date = obs['date']\n",
    "    temp = obs['temperature']\n",
    "    print(f\"{date}, {temp}\")\n",
    "    pass\n",
    "    \n",
    "## is this to start at 0? \n",
    "total_temp = 0\n",
    "count = 0\n",
    "\n",
    "for obs in data['observations']:\n",
    "    total_temp += obs['temperature']\n",
    "    count += 1\n",
    "    pass\n",
    "\n",
    "## don't put it in the loop\n",
    "print(f'Total Temp: {total_temp}')\n",
    "print(f'Count:{count}')\n",
    "\n",
    "avg_temp = total_temp/count  # Replace this\n",
    "print(f'Average temperature: {avg_temp}째F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "093cf2d9-8f63-40c9-b50b-cfe19136f7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Days with precipitation:\n",
      "2023-01-02, 0.5\n",
      "2023-01-04, 0.2\n"
     ]
    }
   ],
   "source": [
    "# 3. Find days with precipitation (9 points)\n",
    "print(\"\\nDays with precipitation:\")\n",
    "\n",
    "for obs in data['observations']:\n",
    "    if obs['precipitation'] > 0:\n",
    "        date = obs['date']\n",
    "        precip = obs['precipitation']\n",
    "        print(f\"{date}, {precip}\")\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e98518-487e-4763-8d26-23724d8ea766",
   "metadata": {},
   "source": [
    "### Now try with a real API :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea609738-1096-4496-8e6a-b3aff6eaa8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a real weather API (you may need to sign up for a free API key)\n",
    "# Example APIs: OpenWeatherMap, NOAA, Weather.gov\n",
    "\n",
    "## I used the QandA to get my site: https://weather-gov.github.io/api/general-faqs\n",
    "\n",
    "#I used weather.gov API of the same location as the example\n",
    "##https://api.weather.gov/points/40.7789,-73.9692\n",
    "##Properties: # What do I use (no precip/temp? in observation)  \n",
    "               #\"forecast\": \"https://api.weather.gov/gridpoints/OKX/34,38/forecast\"\n",
    "               #\"observationStations\": \"https://api.weather.gov/gridpoints/OKX/34,38/stations\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "649bd08a-6df9-41f3-a183-35fbdd77db1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date and Time, Temperature (F)\n",
      "2026-02-17T06:00:00-05:00: 47\n",
      "2026-02-17T18:00:00-05:00: 37\n",
      "2026-02-18T06:00:00-05:00: 45\n",
      "2026-02-18T18:00:00-05:00: 37\n",
      "2026-02-19T06:00:00-05:00: 43\n",
      "2026-02-19T18:00:00-05:00: 35\n",
      "2026-02-20T06:00:00-05:00: 42\n",
      "2026-02-20T18:00:00-05:00: 36\n",
      "2026-02-21T06:00:00-05:00: 43\n",
      "2026-02-21T18:00:00-05:00: 31\n",
      "2026-02-22T06:00:00-05:00: 38\n",
      "2026-02-22T18:00:00-05:00: 27\n",
      "2026-02-23T06:00:00-05:00: 36\n",
      "2026-02-23T18:00:00-05:00: 22\n",
      "Total Temp: 519\n",
      "Count:14\n",
      "Average temperature: 37.07142857142857째F\n"
     ]
    }
   ],
   "source": [
    "wdg = 'https://api.weather.gov/gridpoints/OKX/34,38/forecast'\n",
    "resp = requests.get(wdg)\n",
    "wdg_dat = json.loads(resp.text)\n",
    "wdg_dat\n",
    "\n",
    "##TEMP\n",
    "\n",
    "print(\"Date and Time, Temperature (F)\")\n",
    "for obs in wdg_dat['properties']['periods']:\n",
    "    time = obs['startTime']\n",
    "    wsgtemp = obs['temperature']\n",
    "    print(f\"{time}: {wsgtemp}\")\n",
    "\n",
    "wdgtotal_temp = 0\n",
    "wdgcount = 0\n",
    "\n",
    "for obs in wdg_dat['properties']['periods']:\n",
    "    wdgtotal_temp += obs['temperature']\n",
    "    wdgcount += 1\n",
    "    pass\n",
    "\n",
    "## don't put it in the loop\n",
    "print(f'Total Temp: {wdgtotal_temp}')\n",
    "print(f'Count:{wdgcount}')\n",
    "\n",
    "wdgavg_temp = wdgtotal_temp/wdgcount  # Replace this\n",
    "print(f'Average temperature: {wdgavg_temp}째F')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "72ae7a3f-4f0c-41b8-bd8a-2018e6ef682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Times with precipitation:\n",
      "2026-02-17T06:00:00-05:00, 13\n",
      "2026-02-17T18:00:00-05:00, 7\n",
      "2026-02-18T06:00:00-05:00, 80\n",
      "2026-02-18T18:00:00-05:00, 80\n",
      "2026-02-19T06:00:00-05:00, 16\n",
      "2026-02-19T18:00:00-05:00, 39\n",
      "2026-02-20T06:00:00-05:00, 83\n",
      "2026-02-20T18:00:00-05:00, 83\n",
      "2026-02-21T06:00:00-05:00, 27\n",
      "2026-02-21T18:00:00-05:00, 30\n",
      "2026-02-22T06:00:00-05:00, 48\n",
      "2026-02-22T18:00:00-05:00, 48\n",
      "2026-02-23T06:00:00-05:00, 34\n",
      "2026-02-23T18:00:00-05:00, 16\n"
     ]
    }
   ],
   "source": [
    "# 3. Find days with precipitation (9 points)\n",
    "print(\"\\nTimes with precipitation:\")\n",
    "\n",
    "for obs in wdg_dat['properties']['periods']:\n",
    "    if obs['probabilityOfPrecipitation']['value'] > 0:\n",
    "        wdgdate = obs['startTime']\n",
    "        wdgprecip = obs['probabilityOfPrecipitation']['value']\n",
    "        print(f\"{wdgdate}, {wdgprecip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60121f02-54f1-4a51-87d2-87eab916a546",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 2: Downloading Files with Python\n",
    "#### Pooch is a Python tool for downloading and caching data files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9fa295-b74e-4080-a506-84c8b92b7fd2",
   "metadata": {},
   "source": [
    "### Provided Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ef6faf7e-beb8-415c-9906-8ee556c41da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: /home/nc3225/.cache/pooch/458dad453f6a48e510cd544bef1854e3-air_quality_no2.csv\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "import pooch\n",
    "import os\n",
    "\n",
    "# Set up Pooch to download a file\n",
    "# This example downloads a small air quality dataset\n",
    "file_path = pooch.retrieve(\n",
    "    url='https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_no2.csv',\n",
    "    known_hash=None\n",
    ")\n",
    "\n",
    "print('File downloaded to:', file_path)\n",
    "print('File exists:', os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370aa9d-f680-4de5-94d6-4b66c7db4e24",
   "metadata": {},
   "source": [
    "### Your Tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "951a2905-eb2f-4a04-a11e-6ce65f92f758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 31984 bytes\n",
      "Number of lines: 1036\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Verify the file was downloaded (5 points)\n",
    "# Check the file size\n",
    "file_size = os.path.getsize(file_path)\n",
    "print(f'File size: {file_size} bytes')\n",
    "\n",
    "# YOUR CODE HERE: open the file and count how many lines it has\n",
    "line_count = 0 \n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line_count += 1\n",
    "\n",
    "print(f'Number of lines: {line_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "06354b9f-4d1a-47f9-9dde-bb4633a4d642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Inventory:\n",
      "1. air_quality_no2.csv - Air quality NO2 measurements\n",
      "2. 2017_Antarctica_P3/CSARP_mvdr - Antarctic Data_img\n"
     ]
    }
   ],
   "source": [
    "# 2. Download another file (10 points)\n",
    "# Find a climate dataset online using the sources we talked about in lecture\n",
    "# Download it using Pooch\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "import pooch\n",
    "POOCH = pooch.create(\n",
    "    path=pooch.os_cache(\"2017_Antarctica_P3/CSARP_mvdr\"),\n",
    "    base_url=\"https://data.cresis.ku.edu/data/rds/2017_Antarctica_P3/CSARP_mvdr/20171124_03/\",\n",
    "    registry={\n",
    "        \"Data_img_02_20171124_03_020.mat\": None,\n",
    "    }\n",
    ")\n",
    "\n",
    "local_fname = POOCH.fetch(\"Data_img_02_20171124_03_020.mat\")\n",
    "local_fname\n",
    "\n",
    "\n",
    "# 3. Create a data inventory (5 points)\n",
    "# List all the files you've downloaded in this assignment\n",
    "print('\\nData Inventory:')\n",
    "print('1. air_quality_no2.csv - Air quality NO2 measurements')\n",
    "print('2. 2017_Antarctica_P3/CSARP_mvdr - Antarctic Data_img')\n",
    "# YOUR CODE HERE: add your file from task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85b848-f879-4004-b1bb-79dffbad4bd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 3: Understanding NetCDF Metadata\n",
    "#### NetCDF is a common format for climate data. Even without loading the full dataset, we can examine its metadata using HTTP requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2f7a7-d20e-4160-abf4-66d26aa3ee6d",
   "metadata": {},
   "source": [
    "### Provided Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9e79cb3b-909d-472e-8d8a-c44edd395c8f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "Dataset {\n",
      "    Float32 Y[Y = 360];\n",
      "    Float32 X[X = 720];\n",
      "    Float32 T[T = 324];\n",
      "    Grid {\n",
      "     ARRAY:\n",
      "        Float32 rain[T = 324][Y = 360][X = 720];\n",
      "     MAPS:\n",
      "        Float32 T[T = 324];\n",
      "        Float32 Y[Y = 360];\n",
      "        Float32 X[X = 720];\n",
      "    } rain;\n",
      "} rain;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# OPeNDAP provides metadata in different formats\n",
    "# We'll get basic info about a climate dataset\n",
    "\n",
    "base_url = 'http://iridl.ldeo.columbia.edu/expert/SOURCES/.NOAA/.NCEP/.CPC/.UNIFIED_PRCP/.GAUGE_BASED/.GLOBAL/.v1p0/.Monthly/.RETRO/.rain/dods'\n",
    "\n",
    "# Get DDS (Dataset Descriptor Structure) - describes the structure\n",
    "dds_url = base_url + '.dds'\n",
    "response = requests.get(dds_url)\n",
    "\n",
    "print('Dataset Structure:')\n",
    "print(response.text[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a42ad-0e5c-48fd-91d1-fc8707b7c753",
   "metadata": {},
   "source": [
    "### Your Tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab7584-8537-4505-99f1-d0a72faa3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify dimensions and variables (5 points)\n",
    "# Look at the DDS output above and answer:\n",
    "# - What are the dimension names?\n",
    "# - What is the main variable name?\n",
    "# - Write your answers in a markdown cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ea7d5-4eab-4aaa-8fd6-e2ce9f79cf49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Dimension names = Y: Latitude | X: Longitude | T: Time?\n",
    "#### Main Variable names = rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "83828584-d181-4638-948e-08faec0c74a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes {\n",
      "    Y {\n",
      "        String standard_name \"latitude\";\n",
      "        Float32 pointwidth 0.5;\n",
      "        Int32 gridtype 0;\n",
      "        String units \"degree_north\";\n",
      "    }\n",
      "    X {\n",
      "        String standard_name \"longitude\";\n",
      "        Float32 pointwidth 0.5;\n",
      "        Int32 gridtype 1;\n",
      "        String units \"degree_east\";\n",
      "    }\n",
      "    T {\n",
      "        Float32 pointwidth 1.0;\n",
      "        String calendar \"360\";\n",
      "        Int32 gridtype 0;\n",
      "        String units \"months since 1960-01-01\";\n",
      "    }\n",
      "    rain {\n",
      "        Int32 pointwidth 0;\n",
      "        String standard_name \"lwe_precipitation_rate\";\n",
      "        Float32 file_missing_value -999.0;\n",
      "        String history \"Boxes with less than 0.0% dropped\";\n",
      "        Float32 missing_value NaN;\n",
      "        String units \"mm/day\";\n",
      "        String long_name \"Monthly Precipitation\";\n",
      "    }\n",
      "NC_GLOBAL {\n",
      "    String Conventions \"IRIDL\";\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Get data attributes (5 points)\n",
    "# DAS (Dataset Attribute Structure) contains metadata\n",
    "das_url = base_url + '.das'\n",
    "responsedas = requests.get(das_url)\n",
    "# YOUR CODE HERE: make a request to das_url and print first 1000 characters\n",
    "print(responsedas.text[:1000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce789b77-8075-4242-a4cc-3db6900f549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Document what you learned (5 points)\n",
    "# In a markdown cell, write:\n",
    "# - What does this dataset contain?\n",
    "# - What time period does it cover?\n",
    "# - What geographic region does it cover?\n",
    "# - What are the units of the main variable?\n",
    "# Find this info in the DAS output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd354f5-a50f-4d0e-b9b3-edfc1cf9f57a",
   "metadata": {},
   "source": [
    "#### Contains: Monthly Precipitation Rate over a 360-Day Calendar\n",
    "#### Time-period: Since 1960-01-01\n",
    "#### Geographic Region: Northeast: IRIDL\n",
    "#### Units of Main Variables: mm/day"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo23",
   "language": "python",
   "name": "pangeo23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
